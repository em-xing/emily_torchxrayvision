{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c61c5e",
   "metadata": {},
   "source": [
    "# Windowing Analysis: Visualizing Spline Transformations on Chest X-rays\n",
    "\n",
    "This notebook demonstrates how the learned spline windowing function transforms chest X-ray images. We'll load sample images from the CheXpert dataset and show before/after comparisons of the windowing transformations.\n",
    "\n",
    "## Overview\n",
    "- Load sample chest X-ray images\n",
    "- Apply learned windowing transformations\n",
    "- Visualize before/after comparisons\n",
    "- Analyze the effect on image contrast and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add parent directory to path to import torchxrayvision\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "import torchxrayvision as xrv\n",
    "from torchxrayvision.windowing import SplineWindowingFunction, create_windowing_model\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef63582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some sample chest X-ray images\n",
    "# First, let's create a CheXpert dataset to get sample images\n",
    "dataset_dir = \"/lotterlab/datasets/\"\n",
    "print(f\"Looking for datasets in: {dataset_dir}\")\n",
    "\n",
    "# Create CheXpert dataset\n",
    "try:\n",
    "    dataset = xrv.datasets.CheX_Dataset(\n",
    "        imgpath=os.path.join(dataset_dir, \"CheXpert-v1.0-small\"),\n",
    "        csvpath=os.path.join(dataset_dir, \"CheXpert-v1.0-small/train.csv\"),\n",
    "        transform=None,  # We'll apply transforms manually\n",
    "        views=[\"PA\", \"AP\"]\n",
    "    )\n",
    "    print(f\"Dataset loaded successfully! Total samples: {len(dataset)}\")\n",
    "    \n",
    "    # Get a few sample images\n",
    "    sample_indices = [0, 100, 500, 1000, 2000]  # Different types of cases\n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        if idx < len(dataset):\n",
    "            img, label = dataset[idx]\n",
    "            sample_images.append(img)\n",
    "            sample_labels.append(label)\n",
    "    \n",
    "    print(f\"Loaded {len(sample_images)} sample images\")\n",
    "    print(f\"Image shape: {sample_images[0].shape}\")\n",
    "    print(f\"Image dtype: {sample_images[0].dtype}\")\n",
    "    print(f\"Image range: [{sample_images[0].min():.3f}, {sample_images[0].max():.3f}]\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load CheXpert dataset: {e}\")\n",
    "    print(\"Will create synthetic test images instead...\")\n",
    "    \n",
    "    # Create synthetic chest X-ray-like images for demonstration\n",
    "    sample_images = []\n",
    "    for i in range(5):\n",
    "        # Create a synthetic image with chest-like features\n",
    "        img = torch.randn(1, 512, 512) * 0.2 + 0.5\n",
    "        # Add some structure (ribs, heart shadow, etc.)\n",
    "        center_y, center_x = 256, 256\n",
    "        y, x = torch.meshgrid(torch.arange(512), torch.arange(512), indexing='ij')\n",
    "        \n",
    "        # Heart shadow\n",
    "        heart_mask = ((x - center_x + 50)**2 + (y - center_y + 80)**2) < 8000\n",
    "        img[0][heart_mask] *= 0.7\n",
    "        \n",
    "        # Rib shadows\n",
    "        for rib_y in range(150, 400, 40):\n",
    "            rib_mask = torch.abs(y - rib_y) < 5\n",
    "            img[0][rib_mask] *= 0.8\n",
    "            \n",
    "        sample_images.append(img)\n",
    "    \n",
    "    print(f\"Created {len(sample_images)} synthetic sample images\")\n",
    "    print(f\"Image shape: {sample_images[0].shape}\")\n",
    "    print(f\"Image range: [{sample_images[0].min():.3f}, {sample_images[0].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different windowing functions to compare\n",
    "\n",
    "# 1. Identity windowing (no transformation)\n",
    "identity_windowing = SplineWindowingFunction(n_knots=10, learnable=True, init_nonlinear=False)\n",
    "\n",
    "# 2. Non-linear spline windowing (initial state)\n",
    "nonlinear_windowing = SplineWindowingFunction(n_knots=32, learnable=True, init_nonlinear=True)\n",
    "\n",
    "# 3. Try to load a learned windowing function from a checkpoint if available\n",
    "learned_windowing = None\n",
    "checkpoint_path = \"outputs/chex_full_windowing/chex-resnet50-chex_full_windowing-best_checkpoint.pt\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading learned windowing from: {checkpoint_path}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        # Extract windowing parameters if they exist\n",
    "        if 'windowing_params' in checkpoint:\n",
    "            print(\"Found windowing parameters in checkpoint!\")\n",
    "            windowing_params = checkpoint['windowing_params']\n",
    "            print(f\"Windowing type: {windowing_params.get('type', 'unknown')}\")\n",
    "        else:\n",
    "            print(\"No windowing parameters found in checkpoint\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load checkpoint: {e}\")\n",
    "else:\n",
    "    print(f\"No checkpoint found at {checkpoint_path}\")\n",
    "\n",
    "print(\"Windowing functions created!\")\n",
    "\n",
    "# Let's visualize the windowing functions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot identity windowing\n",
    "x_vals, y_vals = identity_windowing.visualize_mapping(n_points=200)\n",
    "axes[0].plot(x_vals, y_vals, 'b-', linewidth=2, label='Identity Windowing')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Perfect Identity')\n",
    "axes[0].set_title('Identity Windowing Function')\n",
    "axes[0].set_xlabel('Input Intensity')\n",
    "axes[0].set_ylabel('Output Intensity')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Plot non-linear windowing\n",
    "x_vals, y_vals = nonlinear_windowing.visualize_mapping(n_points=200)\n",
    "axes[1].plot(x_vals, y_vals, 'r-', linewidth=2, label='Non-linear Spline Windowing')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Identity')\n",
    "axes[1].set_title('Non-linear Spline Windowing Function')\n",
    "axes[1].set_xlabel('Input Intensity')\n",
    "axes[1].set_ylabel('Output Intensity')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Windowing functions visualized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b390da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply windowing transformations to sample images\n",
    "\n",
    "def apply_windowing_to_images(images, windowing_function, title_suffix=\"\"):\n",
    "    \"\"\"Apply windowing function to a list of images and return results\"\"\"\n",
    "    windowed_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img in images:\n",
    "            # Ensure image is in correct range [0, 1]\n",
    "            img_normalized = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "            \n",
    "            # Apply windowing\n",
    "            windowed_img = windowing_function(img_normalized)\n",
    "            windowed_images.append(windowed_img)\n",
    "    \n",
    "    return windowed_images\n",
    "\n",
    "# Apply different windowing functions\n",
    "print(\"Applying windowing transformations...\")\n",
    "\n",
    "identity_results = apply_windowing_to_images(sample_images, identity_windowing, \"Identity\")\n",
    "nonlinear_results = apply_windowing_to_images(sample_images, nonlinear_windowing, \"Non-linear Spline\")\n",
    "\n",
    "print(f\"Applied windowing to {len(sample_images)} images\")\n",
    "\n",
    "# Create a comprehensive visualization\n",
    "def show_windowing_comparison(original_images, identity_images, nonlinear_images, num_samples=3):\n",
    "    \"\"\"Show before/after comparison of windowing transformations\"\"\"\n",
    "    \n",
    "    num_samples = min(num_samples, len(original_images))\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        img_orig = original_images[i][0].numpy() if isinstance(original_images[i], torch.Tensor) else original_images[i]\n",
    "        axes[i, 0].imshow(img_orig, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Identity windowing\n",
    "        img_id = identity_images[i][0].numpy() if isinstance(identity_images[i], torch.Tensor) else identity_images[i]\n",
    "        axes[i, 1].imshow(img_id, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 1].set_title(f'Identity Windowing {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Non-linear windowing\n",
    "        img_nl = nonlinear_images[i][0].numpy() if isinstance(nonlinear_images[i], torch.Tensor) else nonlinear_images[i]\n",
    "        axes[i, 2].imshow(img_nl, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 2].set_title(f'Non-linear Windowing {i+1}')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Add intensity statistics\n",
    "        orig_stats = f\"Range: [{img_orig.min():.3f}, {img_orig.max():.3f}]\\nMean: {img_orig.mean():.3f}\"\n",
    "        id_stats = f\"Range: [{img_id.min():.3f}, {img_id.max():.3f}]\\nMean: {img_id.mean():.3f}\"\n",
    "        nl_stats = f\"Range: [{img_nl.min():.3f}, {img_nl.max():.3f}]\\nMean: {img_nl.mean():.3f}\"\n",
    "        \n",
    "        axes[i, 0].text(0.02, 0.98, orig_stats, transform=axes[i, 0].transAxes, \n",
    "                       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        axes[i, 1].text(0.02, 0.98, id_stats, transform=axes[i, 1].transAxes, \n",
    "                       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        axes[i, 2].text(0.02, 0.98, nl_stats, transform=axes[i, 2].transAxes, \n",
    "                       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show the comparison\n",
    "print(\"Creating before/after comparison...\")\n",
    "show_windowing_comparison(sample_images, identity_results, nonlinear_results, num_samples=3)\n",
    "\n",
    "print(\"Windowing comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df46f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze intensity distributions and histograms\n",
    "\n",
    "def analyze_intensity_distributions(original_images, windowed_images, windowing_name):\n",
    "    \"\"\"Analyze and plot intensity distributions before/after windowing\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f'Intensity Distribution Analysis - {windowing_name}', fontsize=16)\n",
    "    \n",
    "    # Flatten all images for histogram analysis\n",
    "    orig_pixels = torch.cat([img.flatten() for img in original_images])\n",
    "    wind_pixels = torch.cat([img.flatten() for img in windowed_images])\n",
    "    \n",
    "    # Plot histograms\n",
    "    axes[0, 0].hist(orig_pixels.numpy(), bins=50, alpha=0.7, color='blue', label='Original')\n",
    "    axes[0, 0].set_title('Original Image Histogram')\n",
    "    axes[0, 0].set_xlabel('Pixel Intensity')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].hist(wind_pixels.numpy(), bins=50, alpha=0.7, color='red', label='Windowed')\n",
    "    axes[0, 1].set_title(f'{windowing_name} Histogram')\n",
    "    axes[0, 1].set_xlabel('Pixel Intensity')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overlay histograms for comparison\n",
    "    axes[1, 0].hist(orig_pixels.numpy(), bins=50, alpha=0.5, color='blue', label='Original', density=True)\n",
    "    axes[1, 0].hist(wind_pixels.numpy(), bins=50, alpha=0.5, color='red', label=windowing_name, density=True)\n",
    "    axes[1, 0].set_title('Histogram Overlay')\n",
    "    axes[1, 0].set_xlabel('Pixel Intensity')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Statistical comparison\n",
    "    orig_stats = {\n",
    "        'mean': orig_pixels.mean().item(),\n",
    "        'std': orig_pixels.std().item(),\n",
    "        'min': orig_pixels.min().item(),\n",
    "        'max': orig_pixels.max().item(),\n",
    "        'median': orig_pixels.median().item()\n",
    "    }\n",
    "    \n",
    "    wind_stats = {\n",
    "        'mean': wind_pixels.mean().item(),\n",
    "        'std': wind_pixels.std().item(),\n",
    "        'min': wind_pixels.min().item(),\n",
    "        'max': wind_pixels.max().item(),\n",
    "        'median': wind_pixels.median().item()\n",
    "    }\n",
    "    \n",
    "    # Create statistics table\n",
    "    stats_text = f\"\"\"\n",
    "    Intensity Statistics:\n",
    "    \n",
    "    {'Metric':<10} {'Original':<12} {windowing_name:<15} {'Change':<10}\n",
    "    {'â”€'*50}\n",
    "    {'Mean':<10} {orig_stats['mean']:<12.4f} {wind_stats['mean']:<15.4f} {wind_stats['mean']-orig_stats['mean']:+.4f}\n",
    "    {'Std':<10} {orig_stats['std']:<12.4f} {wind_stats['std']:<15.4f} {wind_stats['std']-orig_stats['std']:+.4f}\n",
    "    {'Min':<10} {orig_stats['min']:<12.4f} {wind_stats['min']:<15.4f} {wind_stats['min']-orig_stats['min']:+.4f}\n",
    "    {'Max':<10} {orig_stats['max']:<12.4f} {wind_stats['max']:<15.4f} {wind_stats['max']-orig_stats['max']:+.4f}\n",
    "    {'Median':<10} {orig_stats['median']:<12.4f} {wind_stats['median']:<15.4f} {wind_stats['median']-orig_stats['median']:+.4f}\n",
    "    \"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes, fontfamily='monospace',\n",
    "                   verticalalignment='top', fontsize=9)\n",
    "    axes[1, 1].set_title('Statistical Comparison')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Analyzing intensity distributions...\")\n",
    "\n",
    "# Analyze non-linear windowing\n",
    "analyze_intensity_distributions(sample_images, nonlinear_results, \"Non-linear Spline\")\n",
    "\n",
    "print(\"Intensity distribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive exploration of windowing parameters\n",
    "\n",
    "def create_custom_windowing(n_knots=16, contrast_boost=1.0, brightness_shift=0.0):\n",
    "    \"\"\"Create a custom windowing function with adjustable parameters\"\"\"\n",
    "    windowing_fn = SplineWindowingFunction(n_knots=n_knots, learnable=True, init_nonlinear=True)\n",
    "    \n",
    "    # Modify the spline weights to simulate different windowing effects\n",
    "    with torch.no_grad():\n",
    "        if hasattr(windowing_fn.spline, 'weights'):\n",
    "            # Apply contrast and brightness adjustments to the weights\n",
    "            weights = windowing_fn.spline.weights\n",
    "            weights *= contrast_boost\n",
    "            weights += brightness_shift\n",
    "    \n",
    "    return windowing_fn\n",
    "\n",
    "def compare_windowing_effects(sample_img_idx=0):\n",
    "    \"\"\"Compare different windowing parameter effects on a single image\"\"\"\n",
    "    \n",
    "    if sample_img_idx >= len(sample_images):\n",
    "        sample_img_idx = 0\n",
    "    \n",
    "    sample_img = sample_images[sample_img_idx]\n",
    "    \n",
    "    # Different windowing configurations\n",
    "    windowing_configs = [\n",
    "        {\"n_knots\": 8, \"contrast_boost\": 1.0, \"brightness_shift\": 0.0, \"name\": \"Standard (8 knots)\"},\n",
    "        {\"n_knots\": 32, \"contrast_boost\": 1.0, \"brightness_shift\": 0.0, \"name\": \"High Resolution (32 knots)\"},\n",
    "        {\"n_knots\": 16, \"contrast_boost\": 1.5, \"brightness_shift\": 0.0, \"name\": \"High Contrast\"},\n",
    "        {\"n_knots\": 16, \"contrast_boost\": 0.7, \"brightness_shift\": 0.0, \"name\": \"Low Contrast\"},\n",
    "        {\"n_knots\": 16, \"contrast_boost\": 1.0, \"brightness_shift\": 0.2, \"name\": \"Bright Shift\"},\n",
    "        {\"n_knots\": 16, \"contrast_boost\": 1.0, \"brightness_shift\": -0.2, \"name\": \"Dark Shift\"}\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Normalize sample image\n",
    "    img_normalized = (sample_img - sample_img.min()) / (sample_img.max() - sample_img.min() + 1e-8)\n",
    "    \n",
    "    for i, config in enumerate(windowing_configs):\n",
    "        windowing_fn = create_custom_windowing(\n",
    "            n_knots=config[\"n_knots\"],\n",
    "            contrast_boost=config[\"contrast_boost\"],\n",
    "            brightness_shift=config[\"brightness_shift\"]\n",
    "        )\n",
    "        \n",
    "        # Apply windowing\n",
    "        with torch.no_grad():\n",
    "            windowed_img = windowing_fn(img_normalized)\n",
    "        \n",
    "        # Display result\n",
    "        img_display = windowed_img[0].numpy() if isinstance(windowed_img, torch.Tensor) else windowed_img\n",
    "        axes[i].imshow(img_display, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i].set_title(f'{config[\"name\"]}\\nRange: [{img_display.min():.3f}, {img_display.max():.3f}]')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Add small histogram\n",
    "        from matplotlib.patches import Rectangle\n",
    "        from matplotlib.patches import FancyBboxPatch\n",
    "        \n",
    "        # Create inset for histogram\n",
    "        hist_data = img_display.flatten()\n",
    "        counts, bins = np.histogram(hist_data, bins=20, range=(0, 1))\n",
    "        \n",
    "        # Add text with statistics\n",
    "        stats_text = f\"Î¼={img_display.mean():.3f}\\nÏƒ={img_display.std():.3f}\"\n",
    "        axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes,\n",
    "                    verticalalignment='top', fontsize=8,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(f'Windowing Effects Comparison - Sample Image {sample_img_idx + 1}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Creating windowing effects comparison...\")\n",
    "compare_windowing_effects(sample_img_idx=0)\n",
    "\n",
    "if len(sample_images) > 1:\n",
    "    print(\"Comparing effects on a different image...\")\n",
    "    compare_windowing_effects(sample_img_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize learned windowing from training checkpoints\n",
    "\n",
    "def load_learned_windowing_from_checkpoint(checkpoint_path):\n",
    "    \"\"\"Load learned windowing function from a training checkpoint\"\"\"\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        \n",
    "        # Check if this is a model with windowing\n",
    "        model_state = checkpoint.get('model_state_dict', checkpoint)\n",
    "        \n",
    "        # Look for windowing function parameters\n",
    "        windowing_keys = [k for k in model_state.keys() if 'windowing_function' in k]\n",
    "        \n",
    "        if windowing_keys:\n",
    "            print(f\"Found {len(windowing_keys)} windowing parameters\")\n",
    "            \n",
    "            # Extract windowing parameters\n",
    "            spline_weights = None\n",
    "            knot_x = None\n",
    "            \n",
    "            for key in windowing_keys:\n",
    "                if 'spline.weights' in key:\n",
    "                    spline_weights = model_state[key]\n",
    "                elif 'spline.knot_x' in key:\n",
    "                    knot_x = model_state[key]\n",
    "            \n",
    "            if spline_weights is not None:\n",
    "                print(f\"Loaded spline weights: shape {spline_weights.shape}\")\n",
    "                \n",
    "                # Create a new windowing function with the learned parameters\n",
    "                n_knots = len(spline_weights) + 1 if spline_weights is not None else 10\n",
    "                windowing_fn = SplineWindowingFunction(n_knots=n_knots, learnable=True, init_nonlinear=False)\n",
    "                \n",
    "                # Load the learned weights\n",
    "                with torch.no_grad():\n",
    "                    if hasattr(windowing_fn.spline, 'weights'):\n",
    "                        windowing_fn.spline.weights.data = spline_weights.clone()\n",
    "                    if knot_x is not None and hasattr(windowing_fn.spline, 'knot_x'):\n",
    "                        windowing_fn.spline.knot_x.data = knot_x.clone()\n",
    "                \n",
    "                return windowing_fn\n",
    "            else:\n",
    "                print(\"No spline weights found in checkpoint\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"No windowing function parameters found in checkpoint\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "# Try to load learned windowing from different possible checkpoint locations\n",
    "checkpoint_locations = [\n",
    "    \"outputs/chex_full_windowing/chex-resnet50-chex_full_windowing-best_checkpoint.pt\",\n",
    "    \"outputs/chex_full_windowing/chex-resnet50-chex_full_windowing-e1_checkpoint.pt\",\n",
    "    \"outputs/chex_windowing_viz/chex-resnet50-chex_windowing_viz-best_checkpoint.pt\",\n",
    "    \"outputs/test_windowing/chex-resnet50-test_windowing-best_checkpoint.pt\"\n",
    "]\n",
    "\n",
    "learned_windowing = None\n",
    "for checkpoint_path in checkpoint_locations:\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"\\\\nTrying checkpoint: {checkpoint_path}\")\n",
    "        learned_windowing = load_learned_windowing_from_checkpoint(checkpoint_path)\n",
    "        if learned_windowing is not None:\n",
    "            print(\"âœ… Successfully loaded learned windowing function!\")\n",
    "            break\n",
    "\n",
    "if learned_windowing is None:\n",
    "    print(\"\\\\nâŒ No learned windowing function found in any checkpoints.\")\n",
    "    print(\"This is expected if training hasn't completed yet.\")\n",
    "    print(\"The notebook will continue with synthetic windowing functions.\")\n",
    "else:\n",
    "    print(\"\\\\nðŸŽ‰ Learned windowing function loaded successfully!\")\n",
    "    \n",
    "    # Visualize the learned windowing function\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot learned windowing curve\n",
    "    x_vals, y_vals = learned_windowing.visualize_mapping(n_points=200)\n",
    "    axes[0].plot(x_vals, y_vals, 'g-', linewidth=3, label='Learned Windowing Function')\n",
    "    axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Identity')\n",
    "    axes[0].set_title('Learned Windowing Function')\n",
    "    axes[0].set_xlabel('Input Intensity')\n",
    "    axes[0].set_ylabel('Output Intensity')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_xlim(0, 1)\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    \n",
    "    # Compare learned vs. initial windowing\n",
    "    x_vals_init, y_vals_init = nonlinear_windowing.visualize_mapping(n_points=200)\n",
    "    axes[1].plot(x_vals_init, y_vals_init, 'r-', linewidth=2, label='Initial Windowing', alpha=0.7)\n",
    "    axes[1].plot(x_vals, y_vals, 'g-', linewidth=3, label='Learned Windowing')\n",
    "    axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Identity')\n",
    "    axes[1].set_title('Learned vs Initial Windowing')\n",
    "    axes[1].set_xlabel('Input Intensity')\n",
    "    axes[1].set_ylabel('Output Intensity')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Apply learned windowing to sample images\n",
    "    if len(sample_images) > 0:\n",
    "        print(\"\\\\nApplying learned windowing to sample images...\")\n",
    "        learned_results = apply_windowing_to_images(sample_images, learned_windowing, \"Learned\")\n",
    "        \n",
    "        # Show comparison with learned windowing\n",
    "        print(\"Creating comparison with learned windowing...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(min(3, len(sample_images)), 4, figsize=(20, 5*min(3, len(sample_images))))\n",
    "        if len(sample_images) == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(min(3, len(sample_images))):\n",
    "            # Original\n",
    "            img_orig = sample_images[i][0].numpy()\n",
    "            axes[i, 0].imshow(img_orig, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 0].set_title(f'Original {i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Identity\n",
    "            img_id = identity_results[i][0].numpy()\n",
    "            axes[i, 1].imshow(img_id, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 1].set_title(f'Identity {i+1}')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Initial non-linear\n",
    "            img_nl = nonlinear_results[i][0].numpy()\n",
    "            axes[i, 2].imshow(img_nl, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 2].set_title(f'Initial Spline {i+1}')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Learned\n",
    "            img_learned = learned_results[i][0].numpy()\n",
    "            axes[i, 3].imshow(img_learned, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, 3].set_title(f'Learned Spline {i+1}')\n",
    "            axes[i, 3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Learned windowing analysis complete! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb958ff",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook demonstrates the effect of learnable spline windowing functions on chest X-ray images. Here's what we observed:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Windowing Function Shapes**: \n",
    "   - Identity windowing preserves the original intensity distribution\n",
    "   - Non-linear spline windowing can enhance contrast and adjust brightness\n",
    "   - Learned windowing functions adapt to the specific dataset characteristics\n",
    "\n",
    "2. **Image Enhancement**:\n",
    "   - Spline windowing can improve contrast in specific intensity ranges\n",
    "   - Different spline parameters create different enhancement effects\n",
    "   - The learned parameters depend on the dataset and training objectives\n",
    "\n",
    "3. **Intensity Distribution Effects**:\n",
    "   - Windowing can reshape the histogram of pixel intensities\n",
    "   - This can help normalize differences between different X-ray machines/protocols\n",
    "   - Useful for removing dataset-specific artifacts while preserving clinical information\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Training Analysis**: Run the full training to see how windowing parameters evolve\n",
    "2. **Clinical Evaluation**: Assess whether windowing improves diagnostic accuracy\n",
    "3. **Comparison Studies**: Compare different windowing initialization strategies\n",
    "4. **Ablation Studies**: Measure the impact of windowing vs. no windowing on model performance\n",
    "\n",
    "### Files Generated:\n",
    "- Windowing visualization plots are saved during training to: `outputs/experiment_name/`\n",
    "- Checkpoints with windowing parameters: `outputs/experiment_name/*checkpoint.pt`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
